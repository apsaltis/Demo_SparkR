{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Initialize the Spark and SparkSQL contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(SparkR)\n",
    "sc <- sparkR.init(\"local[*]\")\n",
    "sqlCtx<- sparkRSQL.init(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Load the 3 datasets from Parquet files into SparkR as DataFrames\n",
    "- **txnsRaw**: Transaction data organized by line-item\n",
    "- **demo**: Demographic data, organized by customer ID\n",
    "- **sample**: A subset of customers who received a DM offer. This is our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txnsRaw<- loadDF(sqlCtx, paste(getwd(), \"/Customer_Transactions.parquet\", sep = \"\"), \"parquet\")\n",
    "demo <- withColumnRenamed(loadDF(sqlCtx, paste(getwd(), \"/Customer_Demographics.parquet\", sep = \"\"), \"parquet\"),\n",
    "                          \"cust_id\", \"ID\")\n",
    "sample <- loadDF(sqlCtx, paste(getwd(), \"/DM_Sample.parquet\", sep = \"\"), \"parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##We can view the schema of any DataFrame with `printSchema()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "printSchema(txnsRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##And take a peak at it with `head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head(txnsRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Now we need to generate a few measures for customer behavior to use in our model:\n",
    "\n",
    "- **txns**: The number of transactions per customer\n",
    "- **spend**: Total expenditure per customer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perCustomer <- agg(groupBy(txnsRaw,\"cust_id\"),\n",
    "                   txns = countDistinct(txnsRaw$day_num),\n",
    "                   spend = sum(txnsRaw$extended_price))\n",
    "\n",
    "head(perCustomer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Next, we'll need to grab the demographic data for all our customers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinToDemo <- select(join(perCustomer, demo),\n",
    "                     demo$\"*\",\n",
    "                     perCustomer$txns, \n",
    "                     perCustomer$spend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##So, what does this join actually look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explain(joinToDemo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##What's wrong with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinToDemo <- select(join(perCustomer, demo, perCustomer$cust_id == demo$ID),\n",
    "                     demo$\"*\",\n",
    "                     perCustomer$txns, \n",
    "                     perCustomer$spend)\n",
    "\n",
    "explain(joinToDemo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Now that we've got all our variables prepared, we need to create separate training and estimation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainDF <- select(join(joinToDemo, sample, joinToDemo$ID == sample$cust_id),\n",
    "                joinToDemo$\"*\",\n",
    "                sample$respondYes)\n",
    "\n",
    "estDF <- select(\n",
    "           filter(\n",
    "             join(joinToDemo, sample, joinToDemo$ID == sample$cust_id, \"left_outer\"),\n",
    "           \"cust_id IS NULL\"),\n",
    "         joinToDemo$\"*\")\n",
    "\n",
    "printSchema(trainDF)\n",
    "\n",
    "persist(estDF, \"MEMORY_ONLY\")\n",
    "count(estDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Now that we've got our data prepped and pared down, we can turn each SparkSQL DataFrame into an R `data.frame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train <- collect(trainDF) ; train$ID <- NULL\n",
    "\n",
    "est <- collect(estDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##How do we go from Spark to R?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class(est)\n",
    "\n",
    "names(est)\n",
    "\n",
    "summary(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Now that we've transitioned to pure R, we can use one of its strongest features: the modeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theModel <- glm(respondYes ~ ., \"binomial\", train)\n",
    "\n",
    "summary(theModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Finally, let's create a custom scoring function that will use R's `predict` method and also output the scores by customer ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictWithID <- function(modObj, data, idField) {\n",
    "  scoringData <- data[, !names(data) %in% as.character(idField)]\n",
    "  scores <- predict(modObj, scoringData, type = \"response\", se.fit = TRUE)\n",
    "  idScores <- data.frame(ID = data[as.character(idField)], Score = scores$fit)\n",
    "  idScores[order( -idScores$Score), ]\n",
    "}\n",
    "\n",
    "testScores <- predictWithID(theModel, est, \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head(testScores, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
